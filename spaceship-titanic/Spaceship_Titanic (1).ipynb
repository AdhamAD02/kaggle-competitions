{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3nGbK6vPBhcq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder , FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBReggreisor as xgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression , SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9Yk06EMgoRc"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/train.csv')\n",
    "test_data = pd.read_csv('/content/test.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HBV3OUXg_3G"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csvlfzl-hBgk"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mF0LE7Am4SB"
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YLPGOpefagM"
   },
   "outputs": [],
   "source": [
    "testing= test_data\n",
    "data[['deck', 'num' , 'side']] = data['Cabin'].str.split('/', expand=True)[[0 , 1,  2]]\n",
    "testing[['deck', 'num' , 'side']] = data['Cabin'].str.split('/', expand=True)[[0 , 1,  2]]\n",
    "data['Group'] = data['PassengerId'].str.split('_' , expand = True)[0].astype(int)\n",
    "test_data['Group'] = test_data['PassengerId'].str.split('_' , expand = True)[0].astype(int)\n",
    "\n",
    "def wow (x):\n",
    "  return x.astype(int)\n",
    "\n",
    "fun = FunctionTransformer(wow)\n",
    "X= data.drop(columns= ['Transported'])\n",
    "y = data['Transported']\n",
    "\n",
    "X_train , X_test , y_train , y_test =  train_test_split(X , y , test_size=0.15, random_state=42)\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "boolean_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')) ,\n",
    "    (\"bool_to_int\" ,fun)\n",
    "    ])\n",
    "\n",
    "numeric_features = [\"Spa\", \"Group\" , \"FoodCourt\" , \"VRDeck\" , \"RoomService\" , \"Age\" , \"ShoppingMall\" , 'num']\n",
    "categorical_features = [\"deck\" ,\"side\" , \"HomePlanet\" , \"Destination\"]\n",
    "boolean_features = [\"CryoSleep\" , \"VIP\"]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('bool', boolean_transformer, boolean_features)\n",
    "        ])\n",
    "\n",
    "\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "\n",
    "X_train_preprocessed = preprocessor.transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "preprocessor.fit(testing)\n",
    "X_test2_preprocessed = preprocessor.transform(testing)\n",
    "\n",
    "ohe_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "\n",
    "\n",
    "feature_names = list(numeric_features) + list(boolean_features)  + list(ohe_feature_names)\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train_preprocessed, columns=feature_names)\n",
    "X_test = pd.DataFrame(X_test_preprocessed, columns=feature_names)\n",
    "testing = pd.DataFrame(X_test2_preprocessed, columns=feature_names)\n",
    "\n",
    "X_train['num'] = X_train['num'].astype(int)\n",
    "X_test['num'] =X_test['num'].astype(int)\n",
    "\n",
    "testing['num']=testing['num'].astype(int)\n",
    "\n",
    "\n",
    "X_train.head()\n",
    "X_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ix064e4O5283"
   },
   "outputs": [],
   "source": [
    "type(X_train['num'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rjn1oHs8kRWQ"
   },
   "outputs": [],
   "source": [
    "z = X_train\n",
    "z['Transported'] = y_train.to_list()\n",
    "X_train = X_train.drop(columns=['Transported'])\n",
    "z.isna().sum()\n",
    "hm = z.corr()\n",
    "plt.figure(figsize=(16 , 9))\n",
    "sb.heatmap(hm , annot=True , fmt=\".2f\"  )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bYZzCBSubpl"
   },
   "outputs": [],
   "source": [
    "bst = XGBClassifier(n_estimators=40, max_depth=6, learning_rate=0.1,min_child_weight= 5,subsample = 1,colsample_bytree= 0.75)\n",
    "bst.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prkM13N_w75p",
    "outputId": "c13e3c8d-beb4-4cf8-c07c-5848ea833e5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7983128834355828"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bst.score(X_test,y_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gElSr-y5QAY"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10, 100]\n",
    "        }\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [3, 5, 7, 9]\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'gamma': [0.1, 0.01, 0.001, 0.0001]\n",
    "        }\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'model': XGBClassifier(),\n",
    "        'params': {\n",
    "            'max_depth': [6, 8, 10],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'n_estimators': [100, 200, 300]\n",
    "        }\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 5, 10, 15],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'GradientBoostingClassifier': {\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'learning_rate': [0.01, 0.1, 1],\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 5, 8]\n",
    "        }\n",
    "    },\n",
    "    'SGDClassifier': {\n",
    "        'model': SGDClassifier(),\n",
    "        'params': {\n",
    "            'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "            'penalty': ['l2', 'l1', 'elasticnet']\n",
    "        }\n",
    "    },\n",
    "    'DecisionTreeClassifier': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_depth': [None, 5, 10, 15]\n",
    "        }\n",
    "    },\n",
    "    'LGBMClassifier': {\n",
    "        'model': LGBMClassifier(),\n",
    "        'params': {\n",
    "            'learning_rate': [0.01, 0.1, 1],\n",
    "            'n_estimators': [20, 40, 60, 80, 100],\n",
    "            'num_leaves': [31, 60, 90, 120]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "best_params_scores = {}\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "\n",
    "    grid_clf = GridSearchCV(model_info['model'], model_info['params'], cv=5)\n",
    "    grid_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    best_params_scores[model_name] = {\n",
    "        'best_params': grid_clf.best_params_,\n",
    "        'best_score': grid_clf.best_score_\n",
    "    }\n",
    "\n",
    "for model_name, params_score in best_params_scores.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Best parameters: {params_score['best_params']}\")\n",
    "    print(f\"Best score: {params_score['best_score']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5r5WXtJgcxaC"
   },
   "outputs": [],
   "source": [
    "lgb = {\n",
    "            'model': LGBMClassifier(),\n",
    "            'params': {\n",
    "            'learning_rate': [0.01, 0.1, 0.05, 1],\n",
    "            'n_estimators': [20, 40, 60, 80, 100],\n",
    "            'num_leaves': [31, 60, 90, 120],\n",
    "            'max_depth': [4, 6],\n",
    "            'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "            'subsample': [0.7, 0.8, 0.9],\n",
    "            'min_child_samples': [1, 5, 10]\n",
    "        }\n",
    "}\n",
    "\n",
    "model = GridSearchCV(lgb['model'], lgb['params'], cv=5 ,\n",
    "                      n_jobs=-1,\n",
    "                      scoring='neg_root_mean_squared_error')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "best_params = model.best_estimator_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_5DYWI7lRGr"
   },
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier(colsample_bytree=0.7, learning_rate=0.01, max_depth=4,\n",
    "               min_child_samples=1, n_estimators=20, subsample=0.7)\n",
    "\n",
    "\n",
    "lgbc.fit(X_train  , y_train)\n",
    "lgbc.score(X_test , y_test)\n",
    "\n",
    "# y_pred = lgbc.predict(testing)\n",
    "# test_data['Transported'] =y_pred\n",
    "# final_test = test_data[['PassengerId' , 'Transported']]\n",
    "# final_test.head()\n",
    "# final_test.to_csv(\"submission.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEB_36Mt7Dcz"
   },
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose = 0 , ignore_warnings = True)\n",
    "models , predictions = clf.fit(X_train, X_test , y_train , y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_3-iA6epmrB"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'lgbm' : LGBMClassifier(colsample_bytree=0.7, learning_rate=0.01, max_depth=4,\n",
    "               min_child_samples=1, n_estimators=20, subsample=0.7),\n",
    "    'random_forest' : RandomForestClassifier(max_depth =15 , min_samples_split=5 , n_estimators=300),\n",
    "    'svc' : SVC(C=10 , gamma=0.1),\n",
    "    'xgb' : XGBClassifier(learning_rate = 0.1 , max_depth=6 , n_estimators= 100)\n",
    "}\n",
    "\n",
    "for name , model in models.items() :\n",
    "  mod= model\n",
    "  mod.fit(X_train , y_train)\n",
    "  score=mod.score(X_test, y_test)\n",
    "  print(score)\n",
    "  # y_pred = mod.predict(testing)\n",
    "  # test_data['Transported'] = y_pred.astype(bool)\n",
    "  # final_test = test_data[['PassengerId' , 'Transported']]\n",
    "\n",
    "  # final_test.head()\n",
    "  # final_test.to_csv(f\"{name}.csv\" , index=False)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
